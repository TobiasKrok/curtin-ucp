# Unix and C Programming Notes <!-- omit from toc --> 

> C89 standard

### Quick commands and code <!-- omit from toc --> 

**Compile to executable**
: `gcc -Wall -ansi -pedantic main.c -o prog`

**C89 way for booleans**
: Paste in the top of file
    ```c
    #define FALSE 0
    #define TRUE !FALSE
    ```
**Header guard**
: Avoids duplicate definitions (may cause compile errors after preprocessor resolves directive)
    ```c
    #ifndef MY_FILE_H  
    #define MY_FILE_H

    // your declarations (and certain types of definitions) here

    #endif
    ```

**Create definitions in gcc**
: You can add definitions as a flag when running gcc
    `gcc <flags> -D name=definition`

     Example: `gcc <flags> -D DEBUG=1`

**Add math library**
: Math library is not a part of standard lib so you need to link it if you use it using `-lm`

  `gcc -Wall -ansi -pedantic -lm main.c -o out`


## Table of contents <!-- omit from toc --> 

- [Compilation](#compilation)
  - [Preprocessor](#preprocessor)
    - [Directive language](#directive-language)
    - [Macros](#macros)
  - [Assembly](#assembly)
  - [Object files](#object-files)
  - [Linking](#linking)
  - [Summary](#summary)
- [Makefile](#makefile)


# Compilation

Compilation is the process of translating high-level programming language code into machine language or executable code that can be understood by a computer. The process of compilation involves several stages, including preprocessing, compilation proper, assembly, and linking.

The first stage of compilation is preprocessing, which is performed by the preprocessor. During preprocessing, the preprocessor reads the source code and performs tasks such as macro expansion, file inclusion, and conditional compilation, as described in my previous answer.

The second stage of compilation is the compilation proper, which is performed by the compiler. During this stage, the compiler reads the preprocessed source code and translates it into assembly language, which is a low-level programming language that is specific to a particular computer architecture.

The third stage of compilation is assembly, which is performed by the assembler. During assembly, the assembler reads the assembly language code generated by the compiler and translates it into machine language or object code, which is a series of binary instructions that can be executed by the computer's processor.

The final stage of compilation is linking, which is performed by the linker. During linking, the linker combines the object code generated by the assembler with any necessary system libraries to create an executable file that can be run on the target system.

In summary, the process of compilation involves converting high-level programming language code into machine language or executable code that can be understood and executed by a computer. This process typically involves several stages, including preprocessing, compilation proper, assembly, and linking, each of which performs a specific task in the overall process.

## Preprocessor

In C programming, a preprocessor is a program that processes the source code before it is compiled. The preprocessor performs various tasks such as macro expansion, file inclusion, conditional compilation, and line control.

One of the main tasks of the preprocessor is macro expansion. Macros are a way of defining a piece of code that can be reused in multiple places in your program. Macros are defined using the #define preprocessor directive, which allows you to give a name to a particular code fragment and use that name instead of writing the full code every time you need it.

`#define SQUARE(x) ((x)*(x))`

This can be used like this:
```c
int main() {
   int a = 5;
   int result = SQUARE(a);
   return 0;
}
```
Other tasks performed by the preprocessor include conditional compilation, which allows you to compile certain parts of your code based on certain conditions, and line control, which allows you to manipulate the line numbering in your code.


You may also define variables that can be used throughout the application

### Directive language

In C programming, directive language refers to a set of preprocessor directives that allow you to control the behavior of the preprocessor and modify the compilation process. These directives are used to define macros, include files, perform conditional compilation, and control line numbering.

Some common directive language constructs in C include:

- `#define`: This directive is used to define macros, which are a way of giving a name to a particular code fragment that can be reused in multiple places in your program. Macros can be used to simplify complex expressions or to provide a shorthand for commonly used code.

- `#include`: This directive is used to include header files in your source code. Header files contain declarations for functions, variables, and other constructs that are used in your program. By including header files, you can reuse code and avoid duplication.

- `#ifdef` and `#ifndef`: These directives are used for conditional compilation. They allow you to compile certain parts of your code based on certain conditions. `#ifdef` tests whether a particular macro is defined, while `#ifndef` tests whether a macro is not defined.

- `#if`, `#elif`, and `#else`: These directives are also used for conditional compilation. They allow you to test a particular condition and compile certain parts of your code based on the result of the test.

- `#line`: This directive allows you to control the line numbering in your source code. You can use it to specify the line number and file name for error messages and debugging information.

Overall, the directive language in C provides a powerful set of tools for controlling the compilation process and customizing the behavior of the preprocessor. By using these directives effectively, you can write more efficient and maintainable code.

### Macros

In C programming, macros are a way of defining a name for a block of code that can be reused multiple times in your program. A macro can be used to define a constant, a function, or a statement that you want to use frequently. Macros are defined using the #define directive and can take arguments to create a flexible and reusable block of code.

The main benefit of using macros is that they can help to simplify complex expressions or provide a shorthand for commonly used code. They can also make your code more readable by giving a name to a particular piece of functionality. Additionally, macros can improve the performance of your code by reducing the amount of code that needs to be executed, since the code is expanded inline by the preprocessor at compile time.

Some common use cases for macros include defining constants, creating simple functions, and creating loops or conditional statements. Overall, macros can be a powerful tool for writing efficient and maintainable code, but it's important to use them judiciously and with care, as they can also make your code harder to read and debug if used improperly.


## Assembly
The assembly step in programming refers to the process of converting assembly code, which is a low-level representation of machine code, into machine code that can be executed by a computer. Assembly code is usually written in a mnemonic format that is easier for humans to read and understand than the corresponding machine code.

The assembly step involves using an assembler program to translate the assembly code into binary machine code that can be executed directly by the computer's CPU. The assembler program reads the assembly code file and translates each instruction into its corresponding machine code representation. It also handles other tasks such as symbol resolution, which involves assigning addresses to memory locations and resolving references to external symbols.

Once the assembly step is complete, the resulting machine code can be loaded into memory and executed by the CPU. This machine code is the lowest-level representation of the program, and is what the computer actually executes to perform the tasks defined by the program.

Overall, the assembly step is a critical part of the programming process, as it allows developers to create low-level programs that can execute directly on a computer's hardware, providing a high degree of control and performance. However, it is also a complex and technical process that requires knowledge of low-level computer architecture and programming languages, and is typically only used for specialized applications where performance or hardware control is critical.

## Object files

Object files are intermediate files generated during the compilation process of a program. They are produced by the compiler when it translates source code into machine code.

An object file contains machine code in a format that can be linked with other object files and libraries to produce an executable file or a shared library. It also contains other information such as symbol tables, relocation information, and debugging information.

The main purpose of object files is to provide a modular approach to building programs, where each source file is compiled into an object file that can be linked together with other object files to create a final executable program. This approach makes it easier to manage and maintain large code bases, as developers can work on individual modules independently and only recompile the modules that have changed, rather than having to recompile the entire program every time a change is made.

Object files can also be used to distribute libraries of reusable code, which can be linked into multiple programs without having to recompile the library code every time. This makes it easier to share code between projects and reduces duplication of effort.

In summary, object files are intermediate files generated during the compilation process that contain machine code and other information needed to link with other object files and libraries to produce an executable program or shared library. They are an important part of the modular approach to building programs and make it easier to manage and maintain large code bases.

Here is an example of an object file:

```c
file format elf64-x86-64

Disassembly of section .text:

0000000000000000 <_start>:
   0:   48 31 c0                xor    %rax,%rax
   3:   b0 01                   mov    $0x1,%al
   5:   48 31 db                xor    %rbx,%rbx
   8:   48 31 c9                xor    %rcx,%rcx
   b:   cd 80                   int    $0x80

```
This object file is written in the ELF format, which is a common format used on Linux and other Unix-like operating systems. It contains a single section, `.text`, which contains the machine code for the program.

The code itself is very simple and just sets up the registers and makes a system call to exit the program. The `_start` label indicates the entry point of the program.

Note that this is just an example and a real-world object file would typically contain much more code and other information, such as symbol tables and debugging information.

## Linking

Linking is the process of combining object files and libraries into a single executable or shared library that can be executed or used by a computer program.

During the compilation process, each source file is compiled into an object file that contains machine code and other information needed to create a program. These object files typically have references to symbols (such as functions or variables) that are defined in other object files or libraries.

The linking process resolves these references by combining the object files and libraries into a single file and ensuring that all references are properly resolved. This involves performing various tasks such as symbol resolution, which involves assigning addresses to memory locations and resolving references to external symbols.

There are two main types of linking: static linking and dynamic linking.

In static linking, the entire executable is created by linking together all the necessary object files and libraries at compile time. This means that the resulting executable contains all the code and data needed to run the program and can be executed independently of any external libraries.

In dynamic linking, the executable is linked with shared libraries at run time rather than at compile time. This means that the executable file itself is smaller and the shared libraries can be shared between multiple programs, reducing disk and memory usage.

Overall, linking is a critical step in the program development process, as it allows developers to create fully executable programs that can be executed or used by other programs.


## Summary

```
           +-------------------+       
           |    Source Code    |       
           +-------------------+       
                    |                     
                    v                     
           +-------------------+       
           |    Compiler       |       
           +-------------------+       
                    |                     
                    v                     
           +-------------------+       
           |   Object Files    |       
           +-------------------+       
                    |                     
                    v                     
           +-------------------+       
           |      Linker       |       
           +-------------------+       
                    |                     
                    v                     
           +-------------------+       
           |   Executable      |       
           +-------------------+       
                    |                     
                    v                     
           +-------------------+       
           |   Operating System|       
           +-------------------+       
                    |                     
                    v                     
           +-------------------+       
           |      Hardware     |       
           +-------------------+       

```

This diagram shows the different stages involved in the process, including:

1. Source code: This is the original code written by the developer.
2. Compiler: This translates the source code into object files that contain machine code.
3. Object files: These are the compiled output files, which typically contain a single module of a program.
4. Linker: This combines the object files into a single executable file by resolving any references between them.
5. Executable: This is the final file that can be run by the computer.
6. Operating system: This is the software that manages the computer's resources and runs the programs.
7. Hardware: This is the physical components of the computer that execute the instructions in the program.

This process is critical to the development and execution of software and involves several different tools and components working together to create a functional program.

# Makefile

See week 2 for example on makefile